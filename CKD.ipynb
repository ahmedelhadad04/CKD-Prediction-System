{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypYYZ7ewEqlb"
      },
      "source": [
        "Uploading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WcBtyG77EcbM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeF_LroAGPbR"
      },
      "outputs": [],
      "source": [
        "path = \"/content/kidney_disease.csv\"\n",
        "data = pd.read_csv(path)\n",
        "\n",
        "print(\"Shape:\", data.shape)\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxf9gIryGrAe"
      },
      "outputs": [],
      "source": [
        "data_clean = data.copy()\n",
        "\n",
        "# Drop common ID column names if they exist\n",
        "for col in [\"id\", \"ID\", \"Id\"]:\n",
        "    if col in data_clean.columns:\n",
        "        data_clean = data_clean.drop(columns=[col])\n",
        "\n",
        "print(\"Shape after dropping ID (if found):\", data_clean.shape)\n",
        "data_clean.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SMmFQW5TGuHP"
      },
      "outputs": [],
      "source": [
        "# Strip whitespace from all object (text) columns\n",
        "for col in data_clean.select_dtypes(include=\"object\").columns:\n",
        "    data_clean[col] = data_clean[col].astype(str).str.strip()\n",
        "\n",
        "# Replace typical missing marker with NaN\n",
        "data_clean = data_clean.replace(\"?\", np.nan)\n",
        "\n",
        "data_clean.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf5FfyxASoPa"
      },
      "outputs": [],
      "source": [
        "for col in [\"pcv\", \"wc\", \"rc\"]:\n",
        "    if col in data_clean.columns:\n",
        "        data_clean[col] = pd.to_numeric(data_clean[col], errors=\"coerce\")\n",
        "\n",
        "data_clean[[\"pcv\",\"wc\",\"rc\"]].dtypes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akQs2n64SrzR"
      },
      "outputs": [],
      "source": [
        "# y is the label column\n",
        "y = data_clean[\"classification\"]\n",
        "\n",
        "# x is everything else\n",
        "x = data_clean.drop(\"classification\", axis=1)\n",
        "\n",
        "print(\"x shape:\", x.shape)\n",
        "print(\"y shape:\", y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MBKStEMMRji"
      },
      "outputs": [],
      "source": [
        "data.drop('id', axis=1, inplace=True)   #dropping ID column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83dTW8GYOqvO"
      },
      "outputs": [],
      "source": [
        "x = data.drop(\"classification\", axis=1)\n",
        "y = data[\"classification\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OhpLKkSO1es"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ar6ipY-TqbU"
      },
      "source": [
        "Data splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtQJUxo5Pbj8"
      },
      "outputs": [],
      "source": [
        "categorical_cols = x.select_dtypes(include=\"object\").columns\n",
        "numerical_cols = x.select_dtypes(exclude=\"object\").columns\n",
        "\n",
        "print(\"Categorical columns:\", categorical_cols)\n",
        "print(\"Numerical columns:\", numerical_cols)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZn_OdQXQCa7"
      },
      "outputs": [],
      "source": [
        " # making a copy of the dataset to experiment cleaning\n",
        " data_clean = data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6spuMAVQypX"
      },
      "outputs": [],
      "source": [
        "data_clean = data_clean.replace(\"?\", np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QW8yiyyFQ16e"
      },
      "outputs": [],
      "source": [
        "for col in [\"pcv\", \"wc\", \"rc\"]:\n",
        "    if col in data_clean.columns:\n",
        "        data_clean[col] = pd.to_numeric(data_clean[col], errors=\"coerce\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o269ayLsQGh9"
      },
      "outputs": [],
      "source": [
        "for col in data_clean.select_dtypes(include=\"object\").columns:\n",
        "    data_clean[col] = data_clean[col].str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4m4ia45RBrA"
      },
      "outputs": [],
      "source": [
        "# Handle numerical missing values\n",
        "for col in numerical_cols:\n",
        "    data_clean[col] = data_clean[col].fillna(data_clean[col].mean())\n",
        "\n",
        "# Handle categorical missing values\n",
        "for col in categorical_cols:\n",
        "    data_clean[col] = data_clean[col].fillna(data_clean[col].mode()[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_5_yOKKRMmB"
      },
      "outputs": [],
      "source": [
        "data_clean.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2I7lzq4RYoi"
      },
      "source": [
        "Label enconding (most categories are binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tnZbsPyRf3E"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "for col in categorical_cols:\n",
        "    data_clean[col] = encoder.fit_transform(data_clean[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anTyMf4mQ7or"
      },
      "outputs": [],
      "source": [
        "x = data_clean.drop(\"classification\", axis=1)\n",
        "y = data_clean[\"classification\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzyUVFUDRmyB"
      },
      "outputs": [],
      "source": [
        "y = y.map({\"ckd\": 1, \"notckd\": 0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xv_ARZA-RyGc"
      },
      "outputs": [],
      "source": [
        "y.value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlPpWaNLN5E7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x[numerical_cols] = scaler.fit_transform(x[numerical_cols])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lsfVDRdSBzN"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "data_clean[numerical_cols] = scaler.fit_transform(data_clean[numerical_cols])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQal2ZEXSGdp"
      },
      "outputs": [],
      "source": [
        "data_clean.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCEHSnkvTHiZ"
      },
      "outputs": [],
      "source": [
        "data_clean[\"classification\"] = data_clean[\"classification\"].map({\n",
        "    \"ckd\": 1,\n",
        "    \"notckd\": 0\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX-upV6ATuYw"
      },
      "source": [
        "Features extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-CJfAUwGiVz"
      },
      "outputs": [],
      "source": [
        "for col in [\"pcv\", \"wc\", \"rc\"]:\n",
        "    if col in data_clean.columns:\n",
        "        data_clean[col] = pd.to_numeric(data_clean[col], errors=\"coerce\")\n",
        "\n",
        "data_clean[[\"pcv\",\"wc\",\"rc\"]].dtypes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1GIqZa-GmWQ"
      },
      "outputs": [],
      "source": [
        "# y is the label column\n",
        "y = data_clean[\"classification\"]\n",
        "\n",
        "# x is everything else\n",
        "x = data_clean.drop(\"classification\", axis=1)\n",
        "\n",
        "print(\"x shape:\", x.shape)\n",
        "print(\"y shape:\", y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYwUWQYeGpC7"
      },
      "outputs": [],
      "source": [
        "categorical_cols = x.select_dtypes(include=\"object\").columns\n",
        "numerical_cols = x.select_dtypes(exclude=\"object\").columns\n",
        "\n",
        "print(\"Categorical columns:\", list(categorical_cols))\n",
        "print(\"Numerical columns:\", list(numerical_cols))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGwpKzfeG1P6"
      },
      "outputs": [],
      "source": [
        "# Numerical: fill NaN with mean\n",
        "for col in numerical_cols:\n",
        "    x[col] = x[col].fillna(x[col].mean())\n",
        "\n",
        "# Categorical: fill NaN with mode\n",
        "for col in categorical_cols:\n",
        "    x[col] = x[col].fillna(x[col].mode()[0])\n",
        "\n",
        "print(\"Total missing values in x:\", x.isna().sum().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZi0wuICG4ay"
      },
      "outputs": [],
      "source": [
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    x[col] = le.fit_transform(x[col])\n",
        "\n",
        "# Verify no object columns remain\n",
        "print(\"Object columns left in x:\", list(x.select_dtypes(include=\"object\").columns))\n",
        "x.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDj1B9ErG7QJ"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "x[numerical_cols] = scaler.fit_transform(x[numerical_cols])\n",
        "\n",
        "# Verify pcv/wc/rc ranges\n",
        "if all(col in x.columns for col in [\"pcv\",\"wc\",\"rc\"]):\n",
        "    print(x[[\"pcv\",\"wc\",\"rc\"]].agg([\"min\",\"max\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dc_O024pG-ZK"
      },
      "outputs": [],
      "source": [
        "# Encode target ONLY if it is still text\n",
        "if y.dtype == \"object\":\n",
        "    y = y.str.strip().map({\"ckd\": 1, \"notckd\": 0})\n",
        "\n",
        "print(y.value_counts())\n",
        "print(y.dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imQQTfJsHQOu"
      },
      "outputs": [],
      "source": [
        "print(\"x dtypes check -> any object?\", x.select_dtypes(include=\"object\").shape[1] > 0)\n",
        "print(\"x NaNs count:\", x.isna().sum().sum())\n",
        "\n",
        "print(\"x shape:\", x.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "\n",
        "x.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLwIasB1ITlk"
      },
      "source": [
        "Feature correlation Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDSk-KBgKdOm"
      },
      "source": [
        "Filter Method: Correlation Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ippfc3jHVjq"
      },
      "outputs": [],
      "source": [
        "# Combine x and y temporarily\n",
        "corr_data = x.copy()\n",
        "corr_data[\"classification\"] = y\n",
        "\n",
        "corr_data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncj13CxiIcDL"
      },
      "outputs": [],
      "source": [
        "corr_matrix = corr_data.corr()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JYEf_YfI1Sm"
      },
      "outputs": [],
      "source": [
        "ckd_corr = corr_matrix[\"classification\"].drop(\"classification\")\n",
        "\n",
        "ckd_corr.sort_values(ascending=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wnv8jgggJFbx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ckd_corr_sorted = ckd_corr.sort_values(key=abs, ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "ckd_corr_sorted.plot(kind=\"bar\")\n",
        "plt.title(\"Feature Correlation with CKD\")\n",
        "plt.ylabel(\"Correlation Coefficient\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHjv2sY6JVSm"
      },
      "outputs": [],
      "source": [
        "threshold = 0.3\n",
        "\n",
        "selected_corr_features = ckd_corr[ckd_corr.abs() >= threshold].index.tolist()\n",
        "\n",
        "print(\"Selected features (correlation-based):\")\n",
        "selected_corr_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1fgNSZIJWfb"
      },
      "outputs": [],
      "source": [
        "x_corr = x[selected_corr_features]\n",
        "\n",
        "print(\"Original shape:\", x.shape)\n",
        "print(\"Correlation-selected shape:\", x_corr.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tne_JxlKKRPq"
      },
      "source": [
        "Filter Method: Chi-Square Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPhsxAbRJZFB"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import chi2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmupwPkuKtox"
      },
      "outputs": [],
      "source": [
        "chi2_scores, chi2_pvalues = chi2(x, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5Wf3IVyK0b2"
      },
      "outputs": [],
      "source": [
        "chi2_results = pd.DataFrame({\n",
        "    \"feature\": x.columns,\n",
        "    \"chi2_score\": chi2_scores,\n",
        "    \"p_value\": chi2_pvalues\n",
        "})\n",
        "\n",
        "chi2_results = chi2_results.sort_values(\"chi2_score\", ascending=False)\n",
        "chi2_results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE1EH0iKLFqI"
      },
      "outputs": [],
      "source": [
        "k = 15\n",
        "selected_chi2_features = chi2_results[\"feature\"].iloc[:k].tolist()\n",
        "\n",
        "selected_chi2_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGIiUwD_LNeW"
      },
      "outputs": [],
      "source": [
        "x_chi2 = x[selected_chi2_features]\n",
        "\n",
        "print(\"Original shape:\", x.shape)\n",
        "print(\"Chi-square selected shape:\", x_chi2.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH-Ir9m8MhbQ"
      },
      "source": [
        "Wrapper Method: Recursive Feature Elimination, RFE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fTCzI9zNGlf"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Et1PqGUlLYGO"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3hm-KMxNLh-"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression model\n",
        "lr_model = LogisticRegression(max_iter=1000, solver=\"liblinear\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDQkzn07NOa5"
      },
      "outputs": [],
      "source": [
        "# Number of features to select\n",
        "n_features = 15\n",
        "\n",
        "rfe = RFE(\n",
        "    estimator=lr_model,\n",
        "    n_features_to_select=n_features\n",
        ")\n",
        "\n",
        "rfe.fit(x, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsgCT9oZNctL"
      },
      "outputs": [],
      "source": [
        "selected_rfe_features = x.columns[rfe.support_].tolist()\n",
        "\n",
        "print(\"Selected features (RFE):\")\n",
        "selected_rfe_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4tkH1VFNeP3"
      },
      "outputs": [],
      "source": [
        "x_rfe = x[selected_rfe_features]\n",
        "\n",
        "print(\"Original shape:\", x.shape)\n",
        "print(\"RFE-selected shape:\", x_rfe.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsbvyHbPNsig"
      },
      "source": [
        "Wrapper Method: Sequential Forward Selection â€“ SFS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7vAL4JrNgnu"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SequentialFeatureSelector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqK1kcZYOKHh"
      },
      "outputs": [],
      "source": [
        "lr_model = LogisticRegression(max_iter=1000, solver=\"liblinear\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDhLwgprOMqK"
      },
      "outputs": [],
      "source": [
        "sfs = SequentialFeatureSelector(\n",
        "    estimator=lr_model,\n",
        "    n_features_to_select=15,\n",
        "    direction=\"forward\",\n",
        "    scoring=\"accuracy\",\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "sfs.fit(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0mebT5hOO9z"
      },
      "outputs": [],
      "source": [
        "selected_sfs_features = x.columns[sfs.get_support()].tolist()\n",
        "\n",
        "print(\"Selected features (SFS):\")\n",
        "selected_sfs_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhAHGCC5OUpW"
      },
      "outputs": [],
      "source": [
        "x_sfs = x[selected_sfs_features]\n",
        "\n",
        "print(\"Original shape:\", x.shape)\n",
        "print(\"SFS-selected shape:\", x_sfs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD2LtOvi-Owq"
      },
      "source": [
        "Training Lasso model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmGPJaGXOW1M"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lasso_model = LogisticRegression(\n",
        "    penalty=\"l1\",\n",
        "    solver=\"liblinear\",\n",
        "    max_iter=1000\n",
        ")\n",
        "\n",
        "lasso_model.fit(x, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qC34ySZ-uMy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Turn coefficients into a labeled Series (feature name -> weight)\n",
        "lasso_coeffs = pd.Series(lasso_model.coef_[0], index=x.columns)\n",
        "\n",
        "# Keep only features with non-zero weights\n",
        "selected_lasso_features = lasso_coeffs[lasso_coeffs != 0].index.tolist()\n",
        "\n",
        "print(\"How many features Lasso kept:\", len(selected_lasso_features))\n",
        "print(\"Lasso selected features:\")\n",
        "selected_lasso_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKeu-Pfq-w_L"
      },
      "outputs": [],
      "source": [
        "x_lasso = x[selected_lasso_features]\n",
        "\n",
        "print(\"Original x shape:\", x.shape)\n",
        "print(\"x_lasso shape:\", x_lasso.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG9k7OUY-11U"
      },
      "source": [
        "Tree-based Embedded Selection :Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2sBw4TA-x4g"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_model.fit(x, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZBJCW1r-6bF"
      },
      "outputs": [],
      "source": [
        "rf_importance = pd.Series(rf_model.feature_importances_, index=x.columns).sort_values(ascending=False)\n",
        "\n",
        "print(\"Top 15 features by Random Forest importance:\")\n",
        "rf_importance.head(15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8s84W5i-8qz"
      },
      "outputs": [],
      "source": [
        "top_n = 15\n",
        "selected_tree_features = rf_importance.head(top_n).index.tolist()\n",
        "\n",
        "x_tree = x[selected_tree_features]\n",
        "\n",
        "print(\"Selected tree-based features:\")\n",
        "selected_tree_features\n",
        "\n",
        "print(\"\\nOriginal x shape:\", x.shape)\n",
        "print(\"x_tree shape:\", x_tree.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CMCYL63_c7t"
      },
      "source": [
        "Feature selection done for each method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBwtZMZA_f4d"
      },
      "source": [
        "Model Training & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZmMOrhq_yR2"
      },
      "source": [
        "Which model performs best, and which feature-selection method helps most?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_-WLSRV_3fZ"
      },
      "source": [
        "Because itâ€™s medical prediction, weâ€™ll focus on:\n",
        "Recall / Sensitivity (catch CKD cases)\n",
        "Precision\n",
        "F1\n",
        "ROC-AUC\n",
        "Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cDIv24H_9O5"
      },
      "source": [
        "dictionary of datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erE4yEJa--9r"
      },
      "outputs": [],
      "source": [
        "datasets = {\n",
        "    \"All features (x)\": x,\n",
        "    \"Correlation (x_corr)\": x_corr,\n",
        "    \"Chi-square (x_chi2)\": x_chi2,\n",
        "    \"RFE (x_rfe)\": x_rfe,\n",
        "    \"SFS (x_sfs)\": x_sfs,\n",
        "    \"Lasso (x_lasso)\": x_lasso,\n",
        "    \"Tree importance (x_tree)\": x_tree\n",
        "}\n",
        "\n",
        "{key: val.shape for key, val in datasets.items()}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_wGRWlc_-hq"
      },
      "source": [
        "Train/test split (stratified)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_G8_UPZ_-Vs"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_dict, X_test_dict = {}, {}\n",
        "\n",
        "for name, Xset in datasets.items():\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        Xset, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "    X_train_dict[name] = X_train\n",
        "    X_test_dict[name] = X_test\n",
        "\n",
        "print(\"y_train distribution:\\n\", y_train.value_counts(normalize=True))\n",
        "print(\"y_test distribution:\\n\", y_test.value_counts(normalize=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHtB3pLNAGOY"
      },
      "source": [
        "Define models to compare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBvgo8H-AES3"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "models = {\n",
        "    \"LogReg\": LogisticRegression(max_iter=1000, solver=\"liblinear\"),\n",
        "    \"SVM (RBF)\": SVC(probability=True),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=300, random_state=42),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0qQa1QDAKfm"
      },
      "source": [
        "Train & evaluate all models on all datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXRE0dABAIlF"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "results = []\n",
        "\n",
        "for dname in datasets.keys():\n",
        "    X_train = X_train_dict[dname]\n",
        "    X_test = X_test_dict[dname]\n",
        "\n",
        "    for mname, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Probabilities for AUC (if available)\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            y_prob = model.predict_proba(X_test)[:, 1]\n",
        "        else:\n",
        "            y_prob = None\n",
        "\n",
        "        row = {\n",
        "            \"Dataset\": dname,\n",
        "            \"Model\": mname,\n",
        "            \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "            \"Precision\": precision_score(y_test, y_pred),\n",
        "            \"Recall\": recall_score(y_test, y_pred),\n",
        "            \"F1\": f1_score(y_test, y_pred),\n",
        "            \"ROC_AUC\": roc_auc_score(y_test, y_prob) if y_prob is not None else np.nan\n",
        "        }\n",
        "        results.append(row)\n",
        "\n",
        "results_df = pd.DataFrame(results).sort_values([\"Recall\", \"F1\", \"Accuracy\"], ascending=False)\n",
        "results_df.head(15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okL7vhEiAPDx"
      },
      "outputs": [],
      "source": [
        "Show the best configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oYFRdBrAP3H"
      },
      "outputs": [],
      "source": [
        "best = results_df.iloc[0]\n",
        "best\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--VgY0PrBfin"
      },
      "source": [
        "Perfect scores on a single split can be misleading, so we applied stratified cross-validation to verify the modelâ€™s generalization and reduce data leakage effects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQNU7YUgBNsZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "models_cv = {\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=300, random_state=42),\n",
        "    \"SVM (RBF)\": SVC(probability=True)\n",
        "}\n",
        "\n",
        "for name, model in models_cv.items():\n",
        "    scores = cross_validate(\n",
        "        model,\n",
        "        x_lasso,\n",
        "        y,\n",
        "        cv=cv,\n",
        "        scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]\n",
        "    )\n",
        "\n",
        "    print(f\"\\n{name} on x_lasso:\")\n",
        "    for metric in scores:\n",
        "        if metric.startswith(\"test_\"):\n",
        "            print(f\"{metric}: {scores[metric].mean():.3f} Â± {scores[metric].std():.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwo-WLEiDFhu"
      },
      "source": [
        "Cross-validation for ALL models on x_lasso\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03yJdDWEBgWc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "models_cv = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, solver=\"liblinear\"),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=300, random_state=42),\n",
        "    \"SVM (RBF)\": SVC(kernel=\"rbf\", probability=True)\n",
        "}\n",
        "\n",
        "cv_results = []\n",
        "\n",
        "for model_name, model in models_cv.items():\n",
        "    scores = cross_validate(\n",
        "        model,\n",
        "        x_lasso,\n",
        "        y,\n",
        "        cv=cv,\n",
        "        scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]\n",
        "    )\n",
        "\n",
        "    cv_results.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Accuracy\": f\"{scores['test_accuracy'].mean():.3f} Â± {scores['test_accuracy'].std():.3f}\",\n",
        "        \"Precision\": f\"{scores['test_precision'].mean():.3f} Â± {scores['test_precision'].std():.3f}\",\n",
        "        \"Recall\": f\"{scores['test_recall'].mean():.3f} Â± {scores['test_recall'].std():.3f}\",\n",
        "        \"F1\": f\"{scores['test_f1'].mean():.3f} Â± {scores['test_f1'].std():.3f}\",\n",
        "        \"ROC_AUC\": f\"{scores['test_roc_auc'].mean():.3f} Â± {scores['test_roc_auc'].std():.3f}\",\n",
        "    })\n",
        "\n",
        "cv_results_df = pd.DataFrame(cv_results)\n",
        "cv_results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxxllwvRFHCn"
      },
      "source": [
        "What makes THESE results credible:\n",
        "âœ… Stratified 5-fold cross-validation\n",
        "âœ… Mean Â± standard deviation reported\n",
        "âœ… Multiple models compared\n",
        "âœ… Fixed feature set (x_lasso)\n",
        "âœ… Performance differences between models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGTNF8qIFlPx"
      },
      "source": [
        "Train final SVM and predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fz_Iv1fdFkyw"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Train-test split (same stratification)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    x_lasso, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Final SVM model\n",
        "final_svm = SVC(kernel=\"rbf\", probability=True)\n",
        "final_svm.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = final_svm.predict(X_test)\n",
        "y_prob = final_svm.predict_proba(X_test)[:, 1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPnHAFdVFd55"
      },
      "source": [
        "Confusion Matrix (Final Model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSBZyW7XFedi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"Not CKD\", \"CKD\"],\n",
        "            yticklabels=[\"Not CKD\", \"CKD\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix â€” SVM (Lasso features)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fwJfqWtF1qJ"
      },
      "source": [
        "ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAbQrApKF1cZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "auc_score = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr, tpr, label=f\"SVM (AUC = {auc_score:.3f})\")\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve â€” SVM (Lasso features)\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5snJIa-G520"
      },
      "source": [
        "------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfFxvXUbHeTE"
      },
      "source": [
        "Calibrate the SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAELws5IHZ5g"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    x_lasso, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Base SVM\n",
        "svm = SVC(kernel=\"rbf\")\n",
        "\n",
        "# Calibrated SVM -> better probabilities\n",
        "final_model = CalibratedClassifierCV(svm, method=\"sigmoid\", cv=5)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "y_prob = final_model.predict_proba(X_test)[:, 1]\n",
        "y_pred = final_model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcDe3wczHfc-"
      },
      "source": [
        "Risk tier function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XD5yaNUHiTy"
      },
      "outputs": [],
      "source": [
        "def risk_tier(p):\n",
        "    # You can tweak thresholds later for your use case\n",
        "    if p < 0.33:\n",
        "        return \"Low\"\n",
        "    elif p < 0.66:\n",
        "        return \"Medium\"\n",
        "    else:\n",
        "        return \"High\"\n",
        "\n",
        "def severity_score(p):\n",
        "    # 0-100 score, easy to display in UI\n",
        "    return int(round(p * 100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lij0IojeHm6S"
      },
      "source": [
        "Create a â€œresultsâ€ table for UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bq5JBtZYHl3G"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "results_ui = X_test.copy()\n",
        "results_ui[\"true_label\"] = y_test.values\n",
        "results_ui[\"pred_label\"] = y_pred\n",
        "results_ui[\"ckd_probability\"] = y_prob\n",
        "results_ui[\"risk_tier\"] = [risk_tier(p) for p in y_prob]\n",
        "results_ui[\"severity_score_0_100\"] = [severity_score(p) for p in y_prob]\n",
        "\n",
        "# Map labels to text for readability\n",
        "results_ui[\"pred_text\"] = results_ui[\"pred_label\"].map({0: \"Not CKD\", 1: \"CKD\"})\n",
        "results_ui[\"true_text\"] = results_ui[\"true_label\"].map({0: \"Not CKD\", 1: \"CKD\"})\n",
        "\n",
        "results_ui[[\"true_text\", \"pred_text\", \"ckd_probability\", \"risk_tier\", \"severity_score_0_100\"]].head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8aTkXBHHuA-"
      },
      "outputs": [],
      "source": [
        "def severity_label(p):\n",
        "    if p < 0.33: return \"Mild risk\"\n",
        "    if p < 0.66: return \"Moderate risk\"\n",
        "    return \"Severe risk\"\n",
        "\n",
        "results_ui[\"severity_label\"] = [severity_label(p) for p in y_prob]\n",
        "results_ui[[\"pred_text\", \"ckd_probability\", \"severity_label\"]].head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKmBEzMDH8pt"
      },
      "source": [
        "----------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xopmc83pH_4e"
      },
      "source": [
        "Risk tier & severity functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fNwB8k9IAQ8"
      },
      "outputs": [],
      "source": [
        "def risk_tier_clinical(p):\n",
        "    if p < 0.20:\n",
        "        return \"Very Low\"\n",
        "    elif p < 0.40:\n",
        "        return \"Low\"\n",
        "    elif p < 0.60:\n",
        "        return \"Moderate\"\n",
        "    elif p < 0.80:\n",
        "        return \"High\"\n",
        "    else:\n",
        "        return \"Very High\"\n",
        "\n",
        "def severity_score(p):\n",
        "    # 0â€“100 scale, easy to visualize in UI\n",
        "    return int(round(p * 100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TAaEwt-IDFq"
      },
      "source": [
        "Apply to final calibrated SVM output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvT9A02jIC5_"
      },
      "outputs": [],
      "source": [
        "results_ui = X_test.copy()\n",
        "\n",
        "results_ui[\"true_label\"] = y_test.values\n",
        "results_ui[\"pred_label\"] = y_pred\n",
        "results_ui[\"ckd_probability\"] = y_prob\n",
        "\n",
        "results_ui[\"risk_tier\"] = results_ui[\"ckd_probability\"].apply(risk_tier_clinical)\n",
        "results_ui[\"severity_score_0_100\"] = results_ui[\"ckd_probability\"].apply(severity_score)\n",
        "\n",
        "# Human-readable labels\n",
        "results_ui[\"pred_text\"] = results_ui[\"pred_label\"].map({0: \"Not CKD\", 1: \"CKD\"})\n",
        "results_ui[\"true_text\"] = results_ui[\"true_label\"].map({0: \"Not CKD\", 1: \"CKD\"})\n",
        "\n",
        "results_ui[[\n",
        "    \"true_text\",\n",
        "    \"pred_text\",\n",
        "    \"ckd_probability\",\n",
        "    \"risk_tier\",\n",
        "    \"severity_score_0_100\"\n",
        "]].head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iprFNk1gIHzO"
      },
      "source": [
        "---------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P829y22QIk7F"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2P01_oIQIHn2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.calibration import CalibratedClassifierCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n4Z9rFnJH4h"
      },
      "source": [
        "Define the exact feature set + mappings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rc64GC06JITm"
      },
      "outputs": [],
      "source": [
        "LASSO_FEATURES = [\"sg\", \"al\", \"hemo\", \"pcv\", \"wc\", \"htn\", \"dm\", \"appet\", \"pe\"]\n",
        "NUM_FEATURES   = [\"sg\", \"al\", \"hemo\", \"pcv\", \"wc\"]\n",
        "CAT_FEATURES   = [\"htn\", \"dm\", \"appet\", \"pe\"]\n",
        "\n",
        "# Encoding maps (adjust if your encoding differs)\n",
        "MAP_YESNO = {\"no\": 0, \"yes\": 1, 0: 0, 1: 1, \"0\": 0, \"1\": 1}\n",
        "MAP_APPET = {\"poor\": 0, \"good\": 1, 0: 0, 1: 1, \"0\": 0, \"1\": 1}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se2PAE3uJKOA"
      },
      "source": [
        "Build a â€œraw-to-model-readyâ€ transformer function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvgdliUDJMRR"
      },
      "outputs": [],
      "source": [
        "def transform_for_model(df_raw, scaler):\n",
        "    df = df_raw.copy()\n",
        "\n",
        "    # Ensure columns exist\n",
        "    for c in LASSO_FEATURES:\n",
        "        if c not in df.columns:\n",
        "            raise ValueError(f\"Missing required feature: {c}\")\n",
        "\n",
        "    # Encode categorical\n",
        "    df[\"htn\"] = df[\"htn\"].map(MAP_YESNO)\n",
        "    df[\"dm\"]  = df[\"dm\"].map(MAP_YESNO)\n",
        "    df[\"pe\"]  = df[\"pe\"].map(MAP_YESNO)\n",
        "    df[\"appet\"] = df[\"appet\"].map(MAP_APPET)\n",
        "\n",
        "    # Safety: convert to numeric\n",
        "    for c in NUM_FEATURES + CAT_FEATURES:\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "    # Scale numeric\n",
        "    df[NUM_FEATURES] = scaler.transform(df[NUM_FEATURES])\n",
        "\n",
        "    # Return in correct order\n",
        "    return df[LASSO_FEATURES]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23aEpks9JPai"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-EyLsv3JPp6"
      },
      "outputs": [],
      "source": [
        "# Use the raw loaded data and clean only the columns we need\n",
        "raw_df = data.copy()\n",
        "\n",
        "# strip and replace missing markers if needed\n",
        "for col in raw_df.select_dtypes(include=\"object\").columns:\n",
        "    raw_df[col] = raw_df[col].astype(str).str.strip()\n",
        "raw_df = raw_df.replace(\"?\", np.nan)\n",
        "\n",
        "# Force numeric for numeric UI inputs\n",
        "for col in [\"sg\",\"al\",\"hemo\",\"pcv\",\"wc\"]:\n",
        "    raw_df[col] = pd.to_numeric(raw_df[col], errors=\"coerce\")\n",
        "\n",
        "# Target\n",
        "y_raw = raw_df[\"classification\"].astype(str).str.strip().map({\"ckd\": 1, \"notckd\": 0})\n",
        "\n",
        "# Keep only rows with known y\n",
        "mask = y_raw.notna()\n",
        "raw_df = raw_df[mask].copy()\n",
        "y_raw = y_raw[mask].astype(int)\n",
        "\n",
        "# Fill missing numeric with mean (simple, consistent)\n",
        "for col in NUM_FEATURES:\n",
        "    raw_df[col] = raw_df[col].fillna(raw_df[col].mean())\n",
        "\n",
        "# Fill missing categorical with mode\n",
        "for col in CAT_FEATURES:\n",
        "    raw_df[col] = raw_df[col].fillna(raw_df[col].mode()[0])\n",
        "\n",
        "raw_df[LASSO_FEATURES].head(), y_raw.value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX3cdRUXJTvK"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# 1. Start from raw data\n",
        "X_raw = raw_df[LASSO_FEATURES].copy()\n",
        "\n",
        "# 2. Encode categorical features safely\n",
        "X_raw[\"htn\"] = X_raw[\"htn\"].map(MAP_YESNO)\n",
        "X_raw[\"dm\"]  = X_raw[\"dm\"].map(MAP_YESNO)\n",
        "X_raw[\"pe\"]  = X_raw[\"pe\"].map(MAP_YESNO)\n",
        "X_raw[\"appet\"] = X_raw[\"appet\"].map(MAP_APPET)\n",
        "\n",
        "# 3. Force numeric conversion\n",
        "for c in NUM_FEATURES + CAT_FEATURES:\n",
        "    X_raw[c] = pd.to_numeric(X_raw[c], errors=\"coerce\")\n",
        "\n",
        "# ðŸ”´ CHECKPOINT â€” verify NaNs exist (for learning)\n",
        "print(\"NaNs before imputation:\\n\", X_raw.isna().sum())\n",
        "\n",
        "# 4. Impute missing values\n",
        "num_imputer = SimpleImputer(strategy=\"mean\")\n",
        "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "\n",
        "X_raw[NUM_FEATURES] = num_imputer.fit_transform(X_raw[NUM_FEATURES])\n",
        "X_raw[CAT_FEATURES] = cat_imputer.fit_transform(X_raw[CAT_FEATURES])\n",
        "\n",
        "# ðŸ”´ CHECKPOINT â€” confirm NaNs are gone\n",
        "print(\"\\nNaNs after imputation:\\n\", X_raw.isna().sum())\n",
        "\n",
        "# 5. Scale numeric features\n",
        "scaler = MinMaxScaler()\n",
        "X_raw[NUM_FEATURES] = scaler.fit_transform(X_raw[NUM_FEATURES])\n",
        "\n",
        "# 6. Final model input\n",
        "X_model = X_raw[LASSO_FEATURES].values\n",
        "y_model = y_raw.values\n",
        "\n",
        "# 7. Train calibrated SVM\n",
        "base_svm = SVC(kernel=\"rbf\")\n",
        "model = CalibratedClassifierCV(base_svm, method=\"sigmoid\", cv=5)\n",
        "model.fit(X_model, y_model)\n",
        "\n",
        "print(\"âœ… Trained calibrated SVM successfully (no NaNs).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaZUhvzIJ3vx"
      },
      "outputs": [],
      "source": [
        "# Background data for SHAP (small sample to keep it fast)\n",
        "bg = X_model[np.random.choice(len(X_model), size=min(80, len(X_model)), replace=False)]\n",
        "\n",
        "artifact = {\n",
        "    \"model\": model,\n",
        "    \"scaler\": scaler,\n",
        "    \"features\": LASSO_FEATURES,\n",
        "    \"num_features\": NUM_FEATURES,\n",
        "    \"cat_features\": CAT_FEATURES,\n",
        "    \"shap_background\": bg\n",
        "}\n",
        "\n",
        "joblib.dump(artifact, \"ckd_ui_artifacts.joblib\")\n",
        "print(\"Saved: ckd_ui_artifacts.joblib\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4owIqOAwKCL5"
      },
      "outputs": [],
      "source": [
        "joblib.dump(artifact, \"ckd_ui_artifacts.joblib\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek70zT7VLCCA"
      },
      "source": [
        "#UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVx2x7oKLDFX"
      },
      "outputs": [],
      "source": [
        "!pip -q install gradio shap joblib matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "i4C8Q9AWLEKI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import gradio as gr\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Load artifacts ---\n",
        "artifact = joblib.load(\"ckd_ui_artifacts.joblib\")\n",
        "model = artifact[\"model\"]\n",
        "scaler = artifact[\"scaler\"]\n",
        "FEATURES = artifact[\"features\"]\n",
        "NUM_FEATURES = artifact[\"num_features\"]\n",
        "CAT_FEATURES = artifact[\"cat_features\"]\n",
        "BG = artifact[\"shap_background\"]\n",
        "\n",
        "# --- Risk tier logic (granular, clinical-feeling) ---\n",
        "def risk_tier_clinical(p):\n",
        "    if p < 0.20:\n",
        "        return \"Very Low\"\n",
        "    elif p < 0.40:\n",
        "        return \"Low\"\n",
        "    elif p < 0.60:\n",
        "        return \"Moderate\"\n",
        "    elif p < 0.80:\n",
        "        return \"High\"\n",
        "    else:\n",
        "        return \"Very High\"\n",
        "\n",
        "def tier_color_hex(tier):\n",
        "    # green â†’ yellow â†’ red\n",
        "    return {\n",
        "        \"Very Low\": \"#2ecc71\",\n",
        "        \"Low\": \"#27ae60\",\n",
        "        \"Moderate\": \"#f1c40f\",\n",
        "        \"High\": \"#e67e22\",\n",
        "        \"Very High\": \"#e74c3c\",\n",
        "    }[tier]\n",
        "\n",
        "def recommendation_text(tier):\n",
        "    # Safe, non-medical-advice phrasing\n",
        "    return {\n",
        "        \"Very Low\": \"Model suggests CKD is unlikely. Continue routine health monitoring.\",\n",
        "        \"Low\": \"Low model-based risk. Consider periodic checkups if symptoms or risk factors exist.\",\n",
        "        \"Moderate\": \"Moderate model-based risk. Consider follow-up lab testing and clinical evaluation.\",\n",
        "        \"High\": \"High model-based risk. Clinical review and confirmatory testing are recommended.\",\n",
        "        \"Very High\": \"Very high model-based risk. Prompt clinical assessment and confirmatory testing are recommended.\",\n",
        "    }[tier]\n",
        "\n",
        "def severity_score(p):\n",
        "    return int(round(p * 100))\n",
        "\n",
        "# --- Build model input row ---\n",
        "def build_model_row(sg, al, hemo, pcv, wc, htn, dm, appet, pe):\n",
        "    # Convert categories to numeric encoding\n",
        "    MAP_YESNO = {\"No\": 0, \"Yes\": 1}\n",
        "    MAP_APPET = {\"Poor\": 0, \"Good\": 1}\n",
        "\n",
        "    row = pd.DataFrame([{\n",
        "        \"sg\": float(sg),\n",
        "        \"al\": float(al),\n",
        "        \"hemo\": float(hemo),\n",
        "        \"pcv\": float(pcv),\n",
        "        \"wc\": float(wc),\n",
        "        \"htn\": MAP_YESNO[htn],\n",
        "        \"dm\": MAP_YESNO[dm],\n",
        "        \"appet\": MAP_APPET[appet],\n",
        "        \"pe\": MAP_YESNO[pe],\n",
        "    }])\n",
        "\n",
        "    # Scale numeric columns using saved scaler\n",
        "    row[NUM_FEATURES] = scaler.transform(row[NUM_FEATURES])\n",
        "\n",
        "    # Ensure correct order\n",
        "    return row[FEATURES].values, row\n",
        "\n",
        "# --- SHAP explainer (KernelExplainer works with any model, but can be slow) ---\n",
        "# We'll initialize once to avoid repeated setup cost.\n",
        "explainer = shap.KernelExplainer(lambda z: model.predict_proba(z)[:, 1], BG)\n",
        "\n",
        "def predict_ckd(sg, al, hemo, pcv, wc, htn, dm, appet, pe):\n",
        "    try:\n",
        "        X_in, row_df = build_model_row(sg, al, hemo, pcv, wc, htn, dm, appet, pe)\n",
        "\n",
        "        prob_ckd = float(model.predict_proba(X_in)[:, 1][0])\n",
        "        pred = int(model.predict(X_in)[0])\n",
        "\n",
        "        tier = risk_tier_clinical(prob_ckd)\n",
        "        color = tier_color_hex(tier)\n",
        "        sev = severity_score(prob_ckd)\n",
        "\n",
        "        # Pretty HTML output\n",
        "        badge = f\"\"\"\n",
        "        <div style=\"padding:12px;border-radius:12px;background:{color};color:white;font-weight:700;\">\n",
        "            Risk Tier: {tier}\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        summary = f\"\"\"\n",
        "        {badge}\n",
        "        <p><b>Prediction:</b> {\"CKD\" if pred==1 else \"Not CKD\"}</p>\n",
        "        <p><b>CKD probability:</b> {prob_ckd:.3f}</p>\n",
        "        <p><b>Severity score:</b> {sev}/100</p>\n",
        "        <p><b>Recommendation:</b> {recommendation_text(tier)}</p>\n",
        "        <hr>\n",
        "        <p style=\"font-size:0.9em;color:#555;\">\n",
        "        Disclaimer: This is a machine-learning demo for educational purposes only and is not medical advice.\n",
        "        </p>\n",
        "        \"\"\"\n",
        "\n",
        "        # --- SHAP explanation ---\n",
        "        # Keep it reasonably fast:\n",
        "        shap_vals = explainer.shap_values(X_in, nsamples=200)\n",
        "        shap_series = pd.Series(shap_vals[0], index=FEATURES).sort_values(key=abs, ascending=False)\n",
        "\n",
        "        # Table output (top 9)\n",
        "        shap_table = shap_series.to_frame(\"SHAP value\").reset_index().rename(columns={\"index\": \"Feature\"})\n",
        "        shap_table[\"Abs(SHAP)\"] = shap_table[\"SHAP value\"].abs()\n",
        "        shap_table = shap_table.sort_values(\"Abs(SHAP)\", ascending=False).drop(columns=[\"Abs(SHAP)\"])\n",
        "\n",
        "        # Bar plot (top 8)\n",
        "        fig, ax = plt.subplots(figsize=(7, 4))\n",
        "        shap_series.iloc[:8][::-1].plot(kind=\"barh\", ax=ax)\n",
        "        ax.set_title(\"Top feature contributions (SHAP)\")\n",
        "        ax.set_xlabel(\"Impact on CKD probability\")\n",
        "        plt.tight_layout()\n",
        "\n",
        "        return summary, shap_table, fig\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"<p style='color:red;'><b>Error:</b> {e}</p>\", None, None\n",
        "\n",
        "# --- Gradio UI ---\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# ðŸ©º CKD Risk Predictor (Model-based)\")\n",
        "    gr.Markdown(\"Educational demo only â€” **not medical advice**. Outputs are *model-based risk tiers*, not clinical staging.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            sg = gr.Number(label=\"Specific Gravity (sg)\", value=1.020)\n",
        "            al = gr.Number(label=\"Albumin (al)\", value=1.0)\n",
        "            hemo = gr.Number(label=\"Hemoglobin (hemo)\", value=12.0)\n",
        "            pcv = gr.Number(label=\"Packed Cell Volume (pcv)\", value=40.0)\n",
        "            wc = gr.Number(label=\"White Blood Cell Count (wc)\", value=8000.0)\n",
        "\n",
        "            htn = gr.Dropdown([\"No\", \"Yes\"], label=\"Hypertension (htn)\", value=\"No\")\n",
        "            dm = gr.Dropdown([\"No\", \"Yes\"], label=\"Diabetes Mellitus (dm)\", value=\"No\")\n",
        "            appet = gr.Dropdown([\"Poor\", \"Good\"], label=\"Appetite (appet)\", value=\"Good\")\n",
        "            pe = gr.Dropdown([\"No\", \"Yes\"], label=\"Pedal Edema (pe)\", value=\"No\")\n",
        "\n",
        "            btn = gr.Button(\"Predict\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_html = gr.HTML(label=\"Result\")\n",
        "            shap_df = gr.Dataframe(label=\"SHAP Contributions (table)\", interactive=False)\n",
        "            shap_plot = gr.Plot(label=\"SHAP Bar Plot\")\n",
        "\n",
        "    btn.click(\n",
        "        predict_ckd,\n",
        "        inputs=[sg, al, hemo, pcv, wc, htn, dm, appet, pe],\n",
        "        outputs=[output_html, shap_df, shap_plot]\n",
        "    )\n",
        "\n",
        "demo.launch(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XvwGhT9j4xlc"
      },
      "outputs": [],
      "source": [
        "# ===== CKD Gradio UI (Full Version: Risk + SHAP Direction + Download Report) =====\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import gradio as gr\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "# ------------------ Load artifacts ------------------\n",
        "artifact = joblib.load(\"ckd_ui_artifacts.joblib\")\n",
        "model = artifact[\"model\"]\n",
        "scaler = artifact[\"scaler\"]\n",
        "FEATURES = artifact[\"features\"]\n",
        "NUM_FEATURES = artifact[\"num_features\"]\n",
        "CAT_FEATURES = artifact[\"cat_features\"]\n",
        "BG = artifact[\"shap_background\"]\n",
        "\n",
        "# ------------------ Risk tier logic (granular) ------------------\n",
        "def risk_tier_clinical(p):\n",
        "    if p < 0.20:\n",
        "        return \"Very Low\"\n",
        "    elif p < 0.40:\n",
        "        return \"Low\"\n",
        "    elif p < 0.60:\n",
        "        return \"Moderate\"\n",
        "    elif p < 0.80:\n",
        "        return \"High\"\n",
        "    else:\n",
        "        return \"Very High\"\n",
        "\n",
        "def tier_color_hex(tier):\n",
        "    return {\n",
        "        \"Very Low\": \"#2ecc71\",\n",
        "        \"Low\": \"#27ae60\",\n",
        "        \"Moderate\": \"#f1c40f\",\n",
        "        \"High\": \"#e67e22\",\n",
        "        \"Very High\": \"#e74c3c\",\n",
        "    }[tier]\n",
        "\n",
        "def recommendation_text(tier):\n",
        "    return {\n",
        "        \"Very Low\": \"Model suggests CKD is unlikely. Continue routine health monitoring.\",\n",
        "        \"Low\": \"Low model-based risk. Consider periodic checkups if symptoms or risk factors exist.\",\n",
        "        \"Moderate\": \"Moderate model-based risk. Consider follow-up lab testing and clinical evaluation.\",\n",
        "        \"High\": \"High model-based risk. Clinical review and confirmatory testing are recommended.\",\n",
        "        \"Very High\": \"Very high model-based risk. Prompt clinical assessment and confirmatory testing are recommended.\",\n",
        "    }[tier]\n",
        "\n",
        "def severity_score(p):\n",
        "    return int(round(p * 100))\n",
        "\n",
        "# ------------------ Build model input ------------------\n",
        "def build_model_row(sg, al, hemo, pcv, wc, htn, dm, appet, pe):\n",
        "    MAP_YESNO = {\"No\": 0, \"Yes\": 1}\n",
        "    MAP_APPET = {\"Poor\": 0, \"Good\": 1}\n",
        "\n",
        "    row = pd.DataFrame([{\n",
        "        \"sg\": float(sg),\n",
        "        \"al\": float(al),\n",
        "        \"hemo\": float(hemo),\n",
        "        \"pcv\": float(pcv),\n",
        "        \"wc\": float(wc),\n",
        "        \"htn\": MAP_YESNO[htn],\n",
        "        \"dm\": MAP_YESNO[dm],\n",
        "        \"appet\": MAP_APPET[appet],\n",
        "        \"pe\": MAP_YESNO[pe],\n",
        "    }])\n",
        "\n",
        "    # Scale numeric columns using saved scaler\n",
        "    row[NUM_FEATURES] = scaler.transform(row[NUM_FEATURES])\n",
        "\n",
        "    # Ensure correct order\n",
        "    return row[FEATURES].values\n",
        "\n",
        "# ------------------ SHAP explainer ------------------\n",
        "# KernelExplainer is universal; BG keeps it fast enough for demo\n",
        "explainer = shap.KernelExplainer(lambda z: model.predict_proba(z)[:, 1], BG)\n",
        "\n",
        "# ------------------ Prediction function ------------------\n",
        "def predict_ckd(sg, al, hemo, pcv, wc, htn, dm, appet, pe):\n",
        "    try:\n",
        "        X_in = build_model_row(sg, al, hemo, pcv, wc, htn, dm, appet, pe)\n",
        "\n",
        "        prob_ckd = float(model.predict_proba(X_in)[:, 1][0])\n",
        "        pred = int(model.predict(X_in)[0])\n",
        "\n",
        "        tier = risk_tier_clinical(prob_ckd)\n",
        "        color = tier_color_hex(tier)\n",
        "        sev = severity_score(prob_ckd)\n",
        "\n",
        "        badge = f\"\"\"\n",
        "        <div style=\"padding:12px;border-radius:12px;background:{color};color:white;font-weight:700;\">\n",
        "            Risk Tier: {tier}\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        summary_html = f\"\"\"\n",
        "        {badge}\n",
        "        <p><b>Prediction:</b> {\"CKD\" if pred==1 else \"Not CKD\"}</p>\n",
        "        <p><b>CKD probability:</b> {prob_ckd:.3f}</p>\n",
        "        <p><b>Severity score:</b> {sev}/100</p>\n",
        "        <p><b>Recommendation:</b> {recommendation_text(tier)}</p>\n",
        "        <hr>\n",
        "        <p style=\"font-size:0.9em;color:#555;\">\n",
        "        Disclaimer: This is a machine-learning demo for educational purposes only and is not medical advice.\n",
        "        </p>\n",
        "        \"\"\"\n",
        "\n",
        "        # ---------- SHAP values ----------\n",
        "        shap_vals = explainer.shap_values(X_in, nsamples=200)\n",
        "        shap_series = pd.Series(shap_vals[0], index=FEATURES)\n",
        "\n",
        "        # Direction helpers\n",
        "        def direction_text(v):\n",
        "            if v > 0:\n",
        "                return \"Toward CKD\"\n",
        "            elif v < 0:\n",
        "                return \"Away from CKD\"\n",
        "            else:\n",
        "                return \"Neutral\"\n",
        "\n",
        "        def arrow(v):\n",
        "            if v > 0:\n",
        "                return \"â¬†ï¸\"\n",
        "            elif v < 0:\n",
        "                return \"â¬‡ï¸\"\n",
        "            return \"âž–\"\n",
        "\n",
        "        shap_table = (\n",
        "            shap_series.to_frame(\"SHAP value\")\n",
        "            .reset_index()\n",
        "            .rename(columns={\"index\": \"Feature\"})\n",
        "        )\n",
        "        shap_table[\"Direction\"] = shap_table[\"SHAP value\"].apply(direction_text)\n",
        "        shap_table[\"Arrow\"] = shap_table[\"SHAP value\"].apply(arrow)\n",
        "        shap_table[\"AbsImpact\"] = shap_table[\"SHAP value\"].abs()\n",
        "        shap_table = shap_table.sort_values(\"AbsImpact\", ascending=False).drop(columns=[\"AbsImpact\"])\n",
        "\n",
        "        # ---------- SHAP plot ----------\n",
        "        topn = 8\n",
        "        top_feats = shap_table[\"Feature\"].iloc[:topn].tolist()\n",
        "        top_vals = shap_series[top_feats]\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(7, 4))\n",
        "        top_vals[::-1].plot(kind=\"barh\", ax=ax)\n",
        "        ax.axvline(0, linewidth=1)\n",
        "        ax.set_title(\"Top feature contributions (SHAP)\\n(+ pushes toward CKD, âˆ’ pushes away)\")\n",
        "        ax.set_xlabel(\"Impact on CKD probability\")\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # ---------- Create downloadable report ----------\n",
        "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        report_path = f\"ckd_report_{ts}.csv\"\n",
        "\n",
        "        inputs_df = pd.DataFrame([{\n",
        "            \"sg\": sg, \"al\": al, \"hemo\": hemo, \"pcv\": pcv, \"wc\": wc,\n",
        "            \"htn\": htn, \"dm\": dm, \"appet\": appet, \"pe\": pe\n",
        "        }])\n",
        "\n",
        "        summary_df = pd.DataFrame([{\n",
        "            \"prediction\": \"CKD\" if pred==1 else \"Not CKD\",\n",
        "            \"ckd_probability\": prob_ckd,\n",
        "            \"risk_tier\": tier,\n",
        "            \"severity_score_0_100\": sev,\n",
        "            \"recommendation\": recommendation_text(tier)\n",
        "        }])\n",
        "\n",
        "        # Write one CSV with sections (simple + reliable)\n",
        "        with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"=== INPUTS ===\\n\")\n",
        "        inputs_df.to_csv(report_path, mode=\"a\", index=False)\n",
        "\n",
        "        with open(report_path, \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"\\n=== PREDICTION SUMMARY ===\\n\")\n",
        "        summary_df.to_csv(report_path, mode=\"a\", index=False)\n",
        "\n",
        "        with open(report_path, \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"\\n=== SHAP EXPLANATION ===\\n\")\n",
        "        shap_table.to_csv(report_path, mode=\"a\", index=False)\n",
        "\n",
        "        return summary_html, shap_table, fig, report_path\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"<p style='color:red;'><b>Error:</b> {e}</p>\", None, None, None\n",
        "\n",
        "# ------------------ Gradio UI ------------------\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# ðŸ©º CKD Risk Predictor (Model-based)\")\n",
        "    gr.Markdown(\"Educational demo only â€” **not medical advice**. Outputs are *model-based risk tiers*, not clinical staging.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            sg = gr.Number(label=\"Specific Gravity (sg)\", value=1.020)\n",
        "            al = gr.Number(label=\"Albumin (al)\", value=1.0)\n",
        "            hemo = gr.Number(label=\"Hemoglobin (hemo)\", value=12.0)\n",
        "            pcv = gr.Number(label=\"Packed Cell Volume (pcv)\", value=40.0)\n",
        "            wc = gr.Number(label=\"White Blood Cell Count (wc)\", value=8000.0)\n",
        "\n",
        "            htn = gr.Dropdown([\"No\", \"Yes\"], label=\"Hypertension (htn)\", value=\"No\")\n",
        "            dm = gr.Dropdown([\"No\", \"Yes\"], label=\"Diabetes Mellitus (dm)\", value=\"No\")\n",
        "            appet = gr.Dropdown([\"Poor\", \"Good\"], label=\"Appetite (appet)\", value=\"Good\")\n",
        "            pe = gr.Dropdown([\"No\", \"Yes\"], label=\"Pedal Edema (pe)\", value=\"No\")\n",
        "\n",
        "            btn = gr.Button(\"Predict\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_html = gr.HTML(label=\"Result\")\n",
        "            shap_df = gr.Dataframe(label=\"SHAP Contributions (with direction)\", interactive=False)\n",
        "            shap_plot = gr.Plot(label=\"SHAP Bar Plot\")\n",
        "            report_file = gr.File(label=\"Download Report (CSV)\")\n",
        "\n",
        "    btn.click(\n",
        "        predict_ckd,\n",
        "        inputs=[sg, al, hemo, pcv, wc, htn, dm, appet, pe],\n",
        "        outputs=[output_html, shap_df, shap_plot, report_file]\n",
        "    )\n",
        "\n",
        "demo.launch(debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}